{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"labeled_data2.csv\")\n",
    "new_data = pd.read_csv(\"api_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  data.sample(frac=1)\n",
    "y    =  data['airline_sentiment']\n",
    "X    =  data\n",
    "Xnew = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns not important\n",
    "X = X.drop(columns=['Unnamed: 0', 'tweet_id','airline_sentiment','airline_sentiment_confidence','negativereason','negativereason_confidence','airline_sentiment_gold','negativereason_gold'])\n",
    "X = X.drop(columns=['text','hashtags','user_timezone','tweet_coord','hashtags','full_text_processed','sents','words','clean_words'])\n",
    "X = X.drop(columns=['user_location','tweet_location','tweet_created','user_acc_date','lang','name','airline','user_verified'])\n",
    "\n",
    "Xnew = Xnew.drop(columns=['Unnamed: 0', 'tweet_id','airline_sentiment','airline_sentiment_confidence','negativereason','negativereason_confidence','airline_sentiment_gold','negativereason_gold'])\n",
    "Xnew = Xnew.drop(columns=['text','hashtags','user_timezone','tweet_coord','hashtags','full_text_processed','sents','words','clean_words'])\n",
    "Xnew = Xnew.drop(columns=['user_location','tweet_location','tweet_created','user_acc_date','lang','name','airline','user_verified'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train/test\n",
    "index  =  round(.7*14640)\n",
    "Xtrain =  X[1:index]\n",
    "Xtest  =  X[index:14640]\n",
    "ytrain =  y[1:index]\n",
    "ytest  =  y[index:14640]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithim Comparisons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial naive bayes\n",
    "\n",
    "t0= time.time()\n",
    "mnb             =  MultinomialNB()\n",
    "\n",
    "mnb.fit(Xtrain,ytrain)\n",
    "\n",
    "t1 = time.time() - t0\n",
    "print(\"Time elapsed: \", t1)\n",
    "\n",
    "mnb.score(Xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST \n",
    "t0= time.time()\n",
    "rf            =  RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "rf.fit(Xtrain,ytrain)\n",
    "\n",
    "t1 = time.time() - t0\n",
    "print(\"Time elapsed: \", t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression \n",
    "t0= time.time()\n",
    "log_model = LogisticRegression(multi_class='multinomial')\n",
    "log_model.fit(Xtrain,ytrain)\n",
    "log_model.score(Xtest,ytest)\n",
    "t1 = time.time() - t0\n",
    "print(\"Time elapsed: \", t1)\n",
    "# So far Logistic model has performed the best on the dataset,\n",
    "# but the model can be improved upon by using regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net logistic Regression\n",
    "# Due to sparsity of bag of words matrix, regularization will probably improve model by a lot \n",
    "t0= time.time()\n",
    "elas_log     =  LogisticRegressionCV(penalty='elasticnet',cv=10,l1_ratios=[0.2,0.5,0.7],max_iter=5000,solver='saga')\n",
    "elas_log.fit(Xtrain,ytrain)\n",
    "elas_log.score(Xtest,ytest)\n",
    "t1 = time.time() - t0\n",
    "print(\"Time elapsed: \", t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=elas_log.predict(Xnew)\n",
    "new_data['predicted_sentiment']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data.to_csv(\"predictions_api_full.csv\",sep=\",\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes Train Accuracy:\",mnb.score(Xtrain,ytrain))\n",
    "print(\"Random Forest Train Accuracy:\",rf.score(Xtrain,ytrain))\n",
    "print(\"Logistic Regression Train Accuracy:\",log_model.score(Xtrain,ytrain))\n",
    "print(\"Elastic Net Train Accuracy:\",elas_log.score(Xtrain,ytrain))\n",
    "\n",
    "print(\"Naive Bayes Test Accuracy:\",mnb.score(Xtest,ytest))\n",
    "print(\"Random Forest Test Accuracy:\",rf.score(Xtest,ytest))\n",
    "print(\"Logistic Regression Test Accuracy:\",log_model.score(Xtest,ytest))\n",
    "print(\"Elastic Net Test Accuracy:\",elas_log.score(Xtest,ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_y=[]\n",
    "for label in ytrain:\n",
    "    if label=='negative':\n",
    "        neg_y.append(1)\n",
    "    else:\n",
    "        neg_y.append(0)\n",
    "        \n",
    "neg_log_model = LogisticRegressionCV(penalty='elasticnet',cv=10,l1_ratios=[0.2,0.5,0.7],max_iter=5000,solver='saga')\n",
    "neg_log_model.fit(Xtrain,neg_y)\n",
    "coefs = neg_log_model.coef_\n",
    "\n",
    "#creating matrix of values \n",
    "coefs = log_model.coef_\n",
    "words_list=list(Xtrain.columns)\n",
    "neg_matrix=pd.DataFrame()\n",
    "neg_matrix['variable']=words_list\n",
    "neg_matrix['coef_value']=coefs[0]\n",
    "neg_matrix=neg_matrix.sort_values(by='coef_value',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_y=[]\n",
    "for label in ytrain:\n",
    "    if label=='positive':\n",
    "        pos_y.append(1)\n",
    "    else:\n",
    "        pos_y.append(0)\n",
    "        \n",
    "pos_log_model = LogisticRegressionCV(penalty='elasticnet',cv=10,l1_ratios=[0.2,0.5,0.7],max_iter=5000,solver='saga')\n",
    "pos_log_model.fit(Xtrain,pos_y)\n",
    "\n",
    "#creating matrix of values \n",
    "coefs        =  pos_log_model.coef_\n",
    "words_list   =  list(Xtrain.columns)\n",
    "pos_matrix   =  pd.DataFrame()\n",
    "\n",
    "pos_matrix['variable']    =  words_list\n",
    "pos_matrix['coef_value']  =  coefs[0]\n",
    "\n",
    "pos_matrix   =  pos_matrix.sort_values(by='coef_value',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_matrix.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_matrix.head(15)\n",
    "#pos_matrix.to_csv(\"pos_coefs.csv\",sep=\",\",encoding='utf-8')\n",
    "#neg_matrix.to_csv(\"neg_coefs.csv\",sep=\",\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
